\documentclass[12pt,a4paper]{article}

\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage[oglav,spisok,boldsect,eqwhole,figwhole,hyperref,hyperprint]{./style/fn2kursstyle}

\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{wrapfig}
\usepackage{amsfonts}

\begin{document}



\section-{Контрольные вопросы}

\begin{enumerate}
	\item \textbf{Вопрос.}  Почему нельзя находить собственные числа матрицы $ A $, прямо решая уравнение $ \det (A - \lambda E) = 0 $, а собственные векторы --- <<по определению>>, решая систему $ (A - \lambda_{i} E) e_{i} = 0 $?
	
	\textbf{Ответ.}
	Для нахождения собственных чисел матрицы, нам надо составить характеристический многочлен и найти его корни. Если исходить непосредственно из определения собственного вектора, то $ e_{i} $ следует искать как нетривиальное решение системы линейных алгебраических уравнений 
	$$ (A - \lambda_{i} E) e_{i} = 0 $$ 
	с вырожденной матрицей $ (A - \lambda_{i} E) $. Но обычно $ \lambda_{i} $ известно лишь приближенно, и в действительности приходится решать систему 
	$$ (A - \lambda_{i}^{\ast} E) e_{i} = 0, $$ 
	где $ \lambda_{i}^{\ast} $ --- достаточно точное приближение к собственному значению $ \lambda_{i} $. Решение данной системы быть только тривиальным, так как матрица $ (A - \lambda_{i}^{\ast} E) $ невырождена. Поэтому непосредственное численное решение не дает возможности вычислить соответствующий собственный вектор.
	
	Кроме того, довольно часто определению подлежат не все собственные значения и собственные векторы, а лишь небольшая их часть. Например, существенный интерес во многих приложениях представляют максимальное или минимальное по модулю собственное значение. 
	
	\item \textbf{Вопрос.}  Докажите, что ортогональное преобразование подобия сохраняет симметрию матрицы.
	
	\textbf{Ответ.}
	Ортогональное преобразование подобия:
	$$ R = P^{-1} A \, P, $$
	где $ P^{-1} = P^{T}, \: A = A^{T} $.
	
	 Тогда 
	\begin{gather*}
		R^{T} = \left( P^{-1} A \, P \right)^{T} = P^{T} \left( A \, P^{-1} \right)^{T} = P^{T} A^{T} \left( P^{-1} \right)^{T} = P^{-1} A \, P = R.
	\end{gather*}
 И следовательно, $R^{T} = R$.
	
	\item  \textbf{Вопрос.} Как преобразование подобия меняет собственные векторы матрицы?
	
	\textbf{Ответ.} Полученная в результате преобразования подобия матрица имеет тот же набор собственных чисел:
	\begin{multline*}
		\det \left( P^{-1} A \, P - \lambda E \right) = \det \left( P^{-1} (A - \lambda E) \, P \right) = \\
		= \det \left( P^{-1} \right) \det \left( A - \lambda E \right) \det \left( P \right) = \det \left( A - \lambda E \right).
	\end{multline*}
	Таким образом, характеристические многочлены и собственные числа матриц $ A $ и $ P^{-1} A \, P $ совпадают. Соответствующие собственные векторы $ x $ и $ x' $ не совпадают, но они связаны равенством $ x = P \, x' $.
	
	\item \textbf{Вопрос.}  Почему на практике матрицу $ A $ подобными преобразованиями вращения приводят только к форме Хессенберга, но не к треугольному виду?
	
	\textbf{Ответ.} $QR$-разложение матрицы требует весьма значительных затрат вычислительных ресурсов, поэтому используются различные методики ускорения $QR$-алгоритма. В частности, затраты времени на вычисления (число арифметических операций) можно сократить, если с помощью подобных преобразований матрицу $A$ предварительно привести к форме Хессенберга. Так как данные матрицы обладают следующими свойствами:
	
	1) матрицы $H^{(k)}$, порождаемые $QR$-алгоритмом из матрицы
	$H^{(0)}$, также являются матрицами Хессенберга;
	
	2) выполнение одной итерации $QR$-алгоритма для матрицы
	Хессенберга требует $O(n^2)$ арифметических операций.
	
	\item \textbf{Вопрос.}  Оцените количество арифметических операций, необходимое для приведения произвольной квадратной матрицы $ A $ к форме Хессенберга.
	
		\textbf{Ответ.} Для вычисления элементов матрицы $ T_{kl} $ требуется 5 операций. Затем необходимо обнулить все элементы ниже диагонали, примыкающей к главной в столбцах с 1 по $ n - 2 $. В $k$-ом столбце необходимо обнулить $ n - k - 1 $ элемент. При обнулении каждого элемента происходит умножение слева и справа на матрицы $ T_{kl} $ и $ T_{kl}^{T} $, что соответственно изменяет в матрице $ A $ $4n - 6 $ элементов. Для изменения одного элемента требуется 2 операции умнржения. В итоге получаем:
	$$\sum \limits_{k = 1}^{n - 2} 5 \cdot (n - k - 1) (4 n - 6 ) \cdot 2 = 10 \cdot (2n^3 - 9n^2+13n-6).$$
	
	\item \textbf{Вопрос.} Сойдется ли алгоритм обратных итераций, если в качестве начального приближения взять собственный вектор, соответствующий другому собственному значению? Что будет в этой ситуации в методе обратной итерации, использующем отношение Рэлея?
	
	\textbf{Ответ.} В качестве начального приближения в методе обратных итераций можно взять любой нормированный вектор. Пусть $e_{i}, \; i = \overline{1,n}$ --- ОНБ из собственных векторов матрицы $A$.
	$$	(A - {\lambda}_{j}^{\ast} E) y = x. $$
	Представим векторы в виде линейных комбинаций собственных векторов:
	$$	y = \sum \limits_{i = 1}^{n} \alpha_{i} e_{i}, \quad x = \sum \limits_{i = 1}^{n} c_{i} e_{i}; $$
	Так как:
	$$ (A - {\lambda}_{j}^{\ast} E) y =	\sum \limits_{i = 1}^{n} \alpha_{i} (\lambda_{i} - {\lambda}_{j}^{\ast})e_{i}, $$
	то $$ 	\sum \limits_{i = 1}^{n} \alpha_{i} (\lambda_{i} - {\lambda}_{j}^{\ast})e_{i} = \sum \limits_{i = 1}^{n} c_{i} e_{i}. $$
	Приравниваем коэффициенты при $e_{i}$, получим:
	$$	\alpha_{i} = \frac{c_{i}}{\lambda_{i} - {\lambda}_{j}^{\ast}}.$$
	Cледовательно,
	$$	y = \sum \limits_{i = 1}^{n} \frac{c_{i}}{\lambda_{i} - {\lambda}_{j}^{\ast}} e_{j} = \frac{1}{\lambda_{i} - {\lambda}_{j}^{\ast}} \left( c_{j} e_{j} + \sum \limits_{i \ne j} \frac{\lambda_{j} - {\lambda}_{j}^{\ast}}{\lambda_{i} - {\lambda}_{j}^{\ast}} c_{i} e_{i} \right).$$
	
	Если в качестве начального приближения взять собственный вектор, соответствующий другому собственному числу:
	$$ y = \frac{1}{\lambda_{i} - {\lambda}_{j}^{\ast}} \left( c_{j} e_{j} + \frac{\lambda_{j} - {\lambda}_{j}^{\ast}}{\lambda_{k} - {\lambda}_{j}^{\ast}} c_{k} e_{k} \right). $$
	Если $ | \lambda_{j} - {\lambda}_{j}^{\ast} | \ll | \lambda_{k} - {\lambda}_{j}^{\ast} | $, то второе слагаемое правой части мало по сравнению с первым. Следовательно  алгоритм сойдется к $e_{j}$.
	Одной из проблем, которые могут возникнуть при использовании метода обратной итерации, является получение хорошего приближения ${\lambda}_{j}^{\ast}$	для собственного значения ${\lambda}_{j}$. Известно, что
	если $A$ — симметричная матрица, то справедлива формула:
	$$\lambda_{min} = {\underset{x\ne 0}{\text{min}}}\rho(x),$$
	где $\rho(x) =\cfrac{(Ax,x)}{(x,x)}$	— отношение Рэлея.
	
	
	Если в методе обратных итераций использовать отношение Рэлея, а в качестве начального приближения $ x^{(0)} $ выбрать собственный вектор $ e_{k} $, соответствующий другому собственному значению, то метод сойдется к собственному числу, соответствующему собственному вектору $ e_{k} $.
	
	\item  \textbf{Вопрос.} Сформулируйте и обоснуйте критерий останова для $ QR $-алгоритма отыскания собственных значений матрицы.
	
	\textbf{Ответ.} Последовательность матриц сходится к верхнетреугольной матрице, на главной диагонали которой стоят собственные значения. Используя
	тот факт, что $QR$-алгоритм последовательно обнуляет элементы начиная с $a_{n,1}$ до $a_{n,n-1}$, итерационный метод поиска собственного значения следует продолжать пока не будет выполняться неравество $|a_{n,n-1}| < \varepsilon$. Затем считая что
	$\lambda_{i} = a_{n,n} $,  переходим к задаче меньшей размерности, то есть ищем спектр матрицы размерности $(n-1)\times(n-1)$.
	
	\item  \textbf{Вопрос.} Предложите возможные варианты условий перехода к алгоритму со сдвигами. Предложите алгоритм выбора величины сдвига.
	
	\textbf{Ответ.} К алгоритму со сдвигами следует переходить, если среди собственных чисел матрицы $А$ есть близкие по величине, то есть для некоторых
	значений $i$ и $j$ $(i > j)$
	$$ \left|\frac{\lambda_{i}}{\lambda_{j}}\right| \approx 1,$$
так как сходимость становится медленной. В этом случае ищут собственные значения не матрицы $A$, а матрицы $\tilde{A} = A -\sigma E$, которые равны $\tilde{\lambda_{i}} = \lambda_{i}-\sigma$. То есть определяют значения, «сдвинутые» относительно искомых собственных значений на величину $\sigma$, которая и называется сдвигом.

Но изначально мы не знаем собственные значения, поэтому условие	перехода к алгоритму со сдвигом следует оценить при помощи теоремы Гершгорина. С помощью данных теорем возможно оценить диапазон собственных значений, и если он меньше 1, то стоит использовать алгоритмы со сдвигом.

 Если $\sigma$ является хорошим приближением для $\lambda_{i}$, то соотношение будет много меньше единицы и алгоритм будет быстро сходиться. Следовательно, $\sigma$ надо стараться выбирать именно так.
	
\item \textbf{Вопрос.} Для чего нужно на каждой итерации нормировать приближение к собственному вектору?
	
\textbf{Ответ.}	Если $ | \lambda | > 1 $, то последовательность норм векторов стремится к бесконечности и при вычислении на ЭВМ возможно переполнение. Eсли $ | \lambda | < 1 $, то последовательность норм векторов стремится к нулю и возможно исчезновение порядка. Для предупреждения этих ситуаций вектор $ x^{k} $ нормируют.

\item \textbf{Вопрос.} Приведите примеры использования собственных чисел и собственных векторов в численных методах.

\textbf{Ответ.} 1) С помощью собственных чисел можно сделать вывод о числе обусловленности матрицы.
	
	2) Интерпретация собственных векторов через приведение кривых второго порядка к каноническому виду. Собственные вектора образуют главные направления кривых второго порядка.
	
	3) В электрических и механических системах собственные числа отвечают собственным частотам колебаний, а собственные векторы характеризуют соответствующие формы (моды) колебаний.
	
	4) Оценка величин критических нагрузок при расчете строительных конструкций основана на информации о собственных значениях и собственных векторах матриц.

\end{enumerate}
\end{document}